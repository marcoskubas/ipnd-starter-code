{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angola', 75.699996949999999)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# First 20 countries with employment data\n",
    "countries = np.array([\n",
    "    'Afghanistan', 'Albania', 'Algeria', 'Angola', 'Argentina',\n",
    "    'Armenia', 'Australia', 'Austria', 'Azerbaijan', 'Bahamas',\n",
    "    'Bahrain', 'Bangladesh', 'Barbados', 'Belarus', 'Belgium',\n",
    "    'Belize', 'Benin', 'Bhutan', 'Bolivia',\n",
    "    'Bosnia and Herzegovina'\n",
    "])\n",
    "\n",
    "# Employment data in 2007 for those 20 countries\n",
    "employment = np.array([\n",
    "    55.70000076,  51.40000153,  50.5       ,  75.69999695,\n",
    "    58.40000153,  40.09999847,  61.5       ,  57.09999847,\n",
    "    60.90000153,  66.59999847,  60.40000153,  68.09999847,\n",
    "    66.90000153,  53.40000153,  48.59999847,  56.79999924,\n",
    "    71.59999847,  58.40000153,  70.40000153,  41.20000076\n",
    "])\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Accessing elements\n",
    "if False:\n",
    "    print countries[0]\n",
    "    print countries[3]\n",
    "\n",
    "# Slicing\n",
    "if False:\n",
    "    print countries[0:3]\n",
    "    print countries[:3]\n",
    "    print countries[17:]\n",
    "    print countries[:]\n",
    "\n",
    "# Element types\n",
    "if False:\n",
    "    print countries.dtype\n",
    "    print employment.dtype\n",
    "    print np.array([0, 1, 2, 3]).dtype\n",
    "    print np.array([1.0, 1.5, 2.0, 2.5]).dtype\n",
    "    print np.array([True, False, True]).dtype\n",
    "    print np.array(['AL', 'AK', 'AZ', 'AR', 'CA']).dtype\n",
    "\n",
    "# Looping\n",
    "if False:\n",
    "    for country in countries:\n",
    "        print 'Examining country {}'.format(country)\n",
    "\n",
    "    for i in range(len(countries)):\n",
    "        country = countries[i]\n",
    "        country_employment = employment[i]\n",
    "        print 'Country {} has employment {}'.format(country,\n",
    "                country_employment)\n",
    "\n",
    "# Numpy functions\n",
    "if False:\n",
    "    print employment.mean()\n",
    "    print employment.std()\n",
    "    print employment.max()\n",
    "    print employment.sum()\n",
    "\n",
    "def max_employment(countries, employment):\n",
    "    max_country = None\n",
    "    max_employment = 0\n",
    "    \n",
    "    for i in range(len(countries)):\n",
    "        country = countries[i]\n",
    "        country_employment = employment[i]\n",
    "        \n",
    "        if country_employment > max_employment:\n",
    "            max_country = country\n",
    "            max_employment = country_employment\n",
    "            \n",
    "    return (max_country, max_employment)\n",
    "\n",
    "print(max_employment(countries, employment))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Angola', 75.699996949999999)\n"
     ]
    }
   ],
   "source": [
    "def max_employment2(countries, employment):\n",
    "    i = employment.argmax()\n",
    "    return (countries[i], employment[i])\n",
    "\n",
    "print(max_employment2(countries, employment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  96.416025  102.644275  101.41129    93.316285  103.455575   98.148215\n",
      "  102.35113    91.77855    92.835475   89.655755   99.218715   98.484275\n",
      "   94.172835  117.335125   98.275645   33.04039    41.905225   90.962965\n",
      "   57.08404    93.06015 ]\n"
     ]
    }
   ],
   "source": [
    "# First 20 countries with school completion data\n",
    "countries = np.array([\n",
    "       'Algeria', 'Argentina', 'Armenia', 'Aruba', 'Austria','Azerbaijan',\n",
    "       'Bahamas', 'Barbados', 'Belarus', 'Belgium', 'Belize', 'Bolivia',\n",
    "       'Botswana', 'Brunei', 'Bulgaria', 'Burkina Faso', 'Burundi',\n",
    "       'Cambodia', 'Cameroon', 'Cape Verde'\n",
    "])\n",
    "\n",
    "# Female school completion rate in 2007 for those 20 countries\n",
    "female_completion = np.array([\n",
    "    97.35583,  104.62379,  103.02998,   95.14321,  103.69019,\n",
    "    98.49185,  100.88828,   95.43974,   92.11484,   91.54804,\n",
    "    95.98029,   98.22902,   96.12179,  119.28105,   97.84627,\n",
    "    29.07386,   38.41644,   90.70509,   51.7478 ,   95.45072\n",
    "])\n",
    "\n",
    "# Male school completion rate in 2007 for those 20 countries\n",
    "male_completion = np.array([\n",
    "     95.47622,  100.66476,   99.7926 ,   91.48936,  103.22096,\n",
    "     97.80458,  103.81398,   88.11736,   93.55611,   87.76347,\n",
    "    102.45714,   98.73953,   92.22388,  115.3892 ,   98.70502,\n",
    "     37.00692,   45.39401,   91.22084,   62.42028,   90.66958\n",
    "])\n",
    "\n",
    "def overall_completion_rate(female_completion, male_completion):\n",
    "    '''\n",
    "    Fill in this function to return a NumPy array containing the overall\n",
    "    school completion rate for each country. The arguments are NumPy\n",
    "    arrays giving the female and male completion of each country in\n",
    "    the same order.\n",
    "    '''\n",
    "    return (female_completion + male_completion) / 2\n",
    "\n",
    "print(overall_completion_rate(female_completion, male_completion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.31965231 -0.780123   -0.87650077  1.82207181 -0.03051941 -1.99019768\n",
      "  0.30144772 -0.16973184  0.23719615  0.84758731  0.18365304  1.00821665\n",
      "  0.87971351 -0.56595055 -1.07996476 -0.20185762  1.38301845 -0.03051941\n",
      "  1.2545153  -1.87240259]\n"
     ]
    }
   ],
   "source": [
    "# First 20 countries with employment data\n",
    "countries = np.array([\n",
    "    'Afghanistan', 'Albania', 'Algeria', 'Angola', 'Argentina',\n",
    "    'Armenia', 'Australia', 'Austria', 'Azerbaijan', 'Bahamas',\n",
    "    'Bahrain', 'Bangladesh', 'Barbados', 'Belarus', 'Belgium',\n",
    "    'Belize', 'Benin', 'Bhutan', 'Bolivia',\n",
    "    'Bosnia and Herzegovina'\n",
    "])\n",
    "\n",
    "# Employment data in 2007 for those 20 countries\n",
    "employment = np.array([\n",
    "    55.70000076,  51.40000153,  50.5       ,  75.69999695,\n",
    "    58.40000153,  40.09999847,  61.5       ,  57.09999847,\n",
    "    60.90000153,  66.59999847,  60.40000153,  68.09999847,\n",
    "    66.90000153,  53.40000153,  48.59999847,  56.79999924,\n",
    "    71.59999847,  58.40000153,  70.40000153,  41.20000076\n",
    "])\n",
    "\n",
    "# Change this country name to change what country will be printed when you\n",
    "# click \"Test Run\". Your function will be called to determine the standardized\n",
    "# score for this country for each of the given 5 Gapminder variables in 2007.\n",
    "# The possible country names are available in the Downloadables section.\n",
    "\n",
    "country_name = 'United States'\n",
    "\n",
    "def standardize_data(values):\n",
    "    '''\n",
    "    Fill in this function to return a standardized version of the given values,\n",
    "    which will be in a NumPy array. Each value should be translated into the\n",
    "    number of standard deviations that value is away from the mean of the data.\n",
    "    (A positive number indicates a value higher than the mean, and a negative\n",
    "    number indicates a value lower than the mean.)\n",
    "    '''\n",
    "    standardize_values = (values - values.mean()) / values.std()\n",
    "    \n",
    "    return standardize_values\n",
    "\n",
    "print(standardize_data(employment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.0540034855\n"
     ]
    }
   ],
   "source": [
    "def mean_time_for_paid_students(time_spent, days_to_cancel):\n",
    "    '''\n",
    "    Fill in this function to calculate the mean time spent in the classroom\n",
    "    for students who stayed enrolled at least (greater than or equal to) 7 days.\n",
    "    Unlike in Lesson 1, you can assume that days_to_cancel will contain only\n",
    "    integers (there are no students who have not canceled yet).\n",
    "    \n",
    "    The arguments are NumPy arrays. time_spent contains the amount of time spent\n",
    "    in the classroom for each student, and days_to_cancel contains the number\n",
    "    of days until each student cancel. The data is given in the same order\n",
    "    in both arrays.\n",
    "    '''\n",
    "    is_paid = days_to_cancel >= 7 \n",
    "    paid_time = time_spent[is_paid]\n",
    "    return paid_time.mean()\n",
    "\n",
    "# Time spent in the classroom in the first week for 20 students\n",
    "time_spent = np.array([\n",
    "       12.89697233,    0.        ,   64.55043217,    0.        ,\n",
    "       24.2315615 ,   39.991625  ,    0.        ,    0.        ,\n",
    "      147.20683783,    0.        ,    0.        ,    0.        ,\n",
    "       45.18261617,  157.60454283,  133.2434615 ,   52.85000767,\n",
    "        0.        ,   54.9204785 ,   26.78142417,    0.\n",
    "])\n",
    "\n",
    "# Days to cancel for 20 students\n",
    "days_to_cancel = np.array([\n",
    "      4,   5,  37,   3,  12,   4,  35,  38,   5,  37,   3,   3,  68,\n",
    "     38,  98,   2, 249,   2, 127,  35\n",
    "])\n",
    "\n",
    "print(mean_time_for_paid_students(time_spent, days_to_cancel)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 5]\n",
      "[1 2 3 4]\n",
      "[100   2   3   4   5]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "b = a\n",
    "a += np.array([1,1,1,1])\n",
    "print b\n",
    "\n",
    "a = np.array([1,2,3,4])\n",
    "b = a\n",
    "a = a + np.array([1,1,1,1])\n",
    "print b\n",
    "\n",
    "a = np.array([1,2,3,4,5])\n",
    "slice = a[:3]\n",
    "slice[0]=100\n",
    "print a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "countries = ['Albania', 'Algeria', 'Andorra', 'Angola', 'Antigua and Barbuda',\n",
    "             'Argentina', 'Armenia', 'Australia', 'Austria', 'Azerbaijan',\n",
    "             'Bahamas', 'Bahrain', 'Bangladesh', 'Barbados', 'Belarus',\n",
    "             'Belgium', 'Belize', 'Benin', 'Bhutan', 'Bolivia']\n",
    "\n",
    "life_expectancy_values = [74.7,  75. ,  83.4,  57.6,  74.6,  75.4,  72.3,  81.5,  80.2,\n",
    "                          70.3,  72.1,  76.4,  68.1,  75.2,  69.8,  79.4,  70.8,  62.7,\n",
    "                          67.3,  70.6]\n",
    "\n",
    "gdp_values = [ 1681.61390973,   2155.48523109,  21495.80508273,    562.98768478,\n",
    "              13495.1274663 ,   9388.68852258,   1424.19056199,  24765.54890176,\n",
    "              27036.48733192,   1945.63754911,  21721.61840978,  13373.21993972,\n",
    "                483.97086804,   9783.98417323,   2253.46411147,  25034.66692293,\n",
    "               3680.91642923,    366.04496652,   1175.92638695,   1132.21387981]\n",
    "\n",
    "# Life expectancy and gdp data in 2007 for 20 countries\n",
    "life_expectancy = pd.Series(life_expectancy_values)\n",
    "gdp = pd.Series(gdp_values)\n",
    "\n",
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Accessing elements and slicing\n",
    "if False:\n",
    "    print life_expectancy[0]\n",
    "    print gdp[3:6]\n",
    "    \n",
    "# Looping\n",
    "if False:\n",
    "    for country_life_expectancy in life_expectancy:\n",
    "        print 'Examining life expectancy {}'.format(country_life_expectancy)\n",
    "        \n",
    "# Pandas functions\n",
    "if False:\n",
    "    print life_expectancy.mean()\n",
    "    print life_expectancy.std()\n",
    "    print gdp.max()\n",
    "    print gdp.sum()\n",
    "\n",
    "# Vectorized operations and index arrays\n",
    "if False:\n",
    "    a = pd.Series([1, 2, 3, 4])\n",
    "    b = pd.Series([1, 2, 1, 2])\n",
    "  \n",
    "    print a + b\n",
    "    print a * 2\n",
    "    print a >= 3\n",
    "    print a[a >= 3]\n",
    "\n",
    "def variable_correlation(variable1, variable2):\n",
    "    '''\n",
    "    Fill in this function to calculate the number of data points for which\n",
    "    the directions of variable1 and variable2 relative to the mean are the\n",
    "    same, and the number of data points for which they are different.\n",
    "    Direction here means whether each value is above or below its mean.\n",
    "    \n",
    "    You can classify cases where the value is equal to the mean for one or\n",
    "    both variables however you like.\n",
    "    \n",
    "    Each argument will be a Pandas series.\n",
    "    \n",
    "    For example, if the inputs were pd.Series([1, 2, 3, 4]) and\n",
    "    pd.Series([4, 5, 6, 7]), then the output would be (4, 0).\n",
    "    This is because 1 and 4 are both below their means, 2 and 5 are both\n",
    "    below, 3 and 6 are both above, and 4 and 7 are both above.\n",
    "    \n",
    "    On the other hand, if the inputs were pd.Series([1, 2, 3, 4]) and\n",
    "    pd.Series([7, 6, 5, 4]), then the output would be (0, 4).\n",
    "    This is because 1 is below its mean but 7 is above its mean, and\n",
    "    so on.\n",
    "    '''\n",
    "    both_above = (variable1 > variable1.mean()) & (variable2 > variable2.mean())\n",
    "    both_below = (variable1 < variable1.mean()) & (variable2 < variable2.mean())\n",
    "    is_same_direction = both_above | both_below\n",
    "    num_same_direction = is_same_direction.sum()        # Replace this with your code\n",
    "    num_different_direction = len(variable1) - num_same_direction   # Replace this with your code\n",
    "    \n",
    "    return (num_same_direction, num_different_direction)\n",
    "\n",
    "variable_correlation(life_expectancy, gdp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Angola', 75.699996949999999)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = [\n",
    "    'Afghanistan', 'Albania', 'Algeria', 'Angola',\n",
    "    'Argentina', 'Armenia', 'Australia', 'Austria',\n",
    "    'Azerbaijan', 'Bahamas', 'Bahrain', 'Bangladesh',\n",
    "    'Barbados', 'Belarus', 'Belgium', 'Belize',\n",
    "    'Benin', 'Bhutan', 'Bolivia', 'Bosnia and Herzegovina',\n",
    "]\n",
    "\n",
    "\n",
    "employment_values = [\n",
    "    55.70000076,  51.40000153,  50.5       ,  75.69999695,\n",
    "    58.40000153,  40.09999847,  61.5       ,  57.09999847,\n",
    "    60.90000153,  66.59999847,  60.40000153,  68.09999847,\n",
    "    66.90000153,  53.40000153,  48.59999847,  56.79999924,\n",
    "    71.59999847,  58.40000153,  70.40000153,  41.20000076,\n",
    "]\n",
    "\n",
    "# Employment data in 2007 for 20 countries\n",
    "employment = pd.Series(employment_values, index=countries)\n",
    "\n",
    "def max_employment(employment):\n",
    "    '''\n",
    "    Fill in this function to return the name of the country\n",
    "    with the highest employment in the given employment\n",
    "    data, and the employment in that country.\n",
    "    \n",
    "    The input will be a Pandas series where the values\n",
    "    are employment and the index is country names.\n",
    "    \n",
    "    Try using the Pandas idxmax() function. Documention can\n",
    "    be found here:\n",
    "    http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.idxmax.html\n",
    "    '''\n",
    "    country = employment.argmax()\n",
    "    max_country = country      # Replace this with your code\n",
    "    max_value = employment[country]   # Replace this with your code\n",
    "\n",
    "    return (max_country, max_value)\n",
    "\n",
    "max_employment(employment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    11\n",
      "b    22\n",
      "c    33\n",
      "d    44\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Change False to True for each block of code to see what it does\n",
    "\n",
    "# Addition when indexes are the same\n",
    "if True:\n",
    "    s1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "    s2 = pd.Series([10, 20, 30, 40], index=['a', 'b', 'c', 'd'])\n",
    "    print s1 + s2\n",
    "\n",
    "# Indexes have same elements in a different order\n",
    "if False:\n",
    "    s1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "    s2 = pd.Series([10, 20, 30, 40], index=['b', 'd', 'a', 'c'])\n",
    "    print s1 + s2\n",
    "\n",
    "# Indexes overlap, but do not have exactly the same elements\n",
    "if False:\n",
    "    s1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "    s2 = pd.Series([10, 20, 30, 40], index=['c', 'd', 'e', 'f'])\n",
    "    print s1 + s2\n",
    "\n",
    "# Indexes do not overlap\n",
    "if False:\n",
    "    s1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "    s2 = pd.Series([10, 20, 30, 40], index=['e', 'f', 'g', 'h'])\n",
    "    print s1 + s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c    13.0\n",
      "d    24.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Dropna\n",
    "s1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "s2 = pd.Series([10, 20, 30, 40], index=['c', 'd', 'e', 'f'])\n",
    "sum_result = s1 + s2\n",
    "print(sum_result.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a     1.0\n",
      "b     2.0\n",
      "c    13.0\n",
      "d    24.0\n",
      "e    30.0\n",
      "f    40.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "### 19.Quiz: Preenchendo valores faltantes ###\n",
    "\n",
    "s1 = pd.Series([1, 2, 3, 4], index=['a', 'b', 'c', 'd'])\n",
    "s2 = pd.Series([10, 20, 30, 40], index=['c', 'd', 'e', 'f'])\n",
    "\n",
    "# Try to write code that will add the 2 previous series together,\n",
    "# but treating missing values from either series as 0. The result\n",
    "# when printed out should be similar to the following line:\n",
    "# print pd.Series([1, 2, 13, 24, 30, 40], index=['a', 'b', 'c', 'd', 'e', 'f'])\n",
    "\n",
    "#sum_result = s1 + s2\n",
    "sum_result = s1.add(s2, fill_value=0)\n",
    "print(sum_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             Agassi, Andre\n",
      "1              Bonds, Barry\n",
      "2     Columbus, Christopher\n",
      "3             Defoe, Daniel\n",
      "4           Estevez, Emilio\n",
      "5          Flintstone, Fred\n",
      "6              Garbo, Greta\n",
      "7          Humbert, Humbert\n",
      "8               Ilych, Ivan\n",
      "9              Joyce, James\n",
      "10         Knightley, Keira\n",
      "11               Lane, Lois\n",
      "12              Myers, Mike\n",
      "13              Nolte, Nick\n",
      "14           Osbourne, Ozzy\n",
      "15           Picasso, Pablo\n",
      "16       Quirrell, Quirinus\n",
      "17             Ray, Rachael\n",
      "18          Sarandon, Susan\n",
      "19             Turner, Tina\n",
      "20           Urbina, Ugueth\n",
      "21            Vaughn, Vince\n",
      "22          Wilson, Woodrow\n",
      "23             Yamada, Yoji\n",
      "24         Zidane, Zinedine\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "### 20. Quiz: Série apply() do Pandas ###\n",
    "\n",
    "# Change False to True to see what the following block of code does\n",
    "\n",
    "# Example pandas apply() usage (although this could have been done\n",
    "# without apply() using vectorized operations)\n",
    "if False:\n",
    "    s = pd.Series([1, 2, 3, 4, 5])\n",
    "    def add_one(x):\n",
    "        return x + 1\n",
    "    print s.apply(add_one)\n",
    "\n",
    "names = pd.Series([\n",
    "    'Andre Agassi',\n",
    "    'Barry Bonds',\n",
    "    'Christopher Columbus',\n",
    "    'Daniel Defoe',\n",
    "    'Emilio Estevez',\n",
    "    'Fred Flintstone',\n",
    "    'Greta Garbo',\n",
    "    'Humbert Humbert',\n",
    "    'Ivan Ilych',\n",
    "    'James Joyce',\n",
    "    'Keira Knightley',\n",
    "    'Lois Lane',\n",
    "    'Mike Myers',\n",
    "    'Nick Nolte',\n",
    "    'Ozzy Osbourne',\n",
    "    'Pablo Picasso',\n",
    "    'Quirinus Quirrell',\n",
    "    'Rachael Ray',\n",
    "    'Susan Sarandon',\n",
    "    'Tina Turner',\n",
    "    'Ugueth Urbina',\n",
    "    'Vince Vaughn',\n",
    "    'Woodrow Wilson',\n",
    "    'Yoji Yamada',\n",
    "    'Zinedine Zidane'\n",
    "])\n",
    "\n",
    "def reverse_name(name):\n",
    "    split_name = name.split(\" \")\n",
    "    first_name = split_name[0]\n",
    "    last_name = split_name[1]\n",
    "    return last_name + ', ' + first_name\n",
    "\n",
    "def reverse_names(names):\n",
    "    '''\n",
    "    Fill in this function to return a new series where each name\n",
    "    in the input series has been transformed from the format\n",
    "    \"Firstname Lastname\" to \"Lastname, FirstName\".\n",
    "    \n",
    "    Try to use the Pandas apply() function rather than a loop.\n",
    "    '''\n",
    "    return names.apply(reverse_name)\n",
    "\n",
    "print reverse_names(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File /datasets/ud170/gapminder/employment_above_15.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-696cdd97f93f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'/datasets/ud170/gapminder/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0memployment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'employment_above_15.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Country'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mfemale_completion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'female_completion_rate.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Country'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmale_completion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'male_completion_rate.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Country'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MARCOS\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MARCOS\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MARCOS\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MARCOS\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    964\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MARCOS\\Anaconda2\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1582\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1584\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: File /datasets/ud170/gapminder/employment_above_15.csv does not exist"
     ]
    }
   ],
   "source": [
    "### 21. Quiz: Gráfico no Pandas ###\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The following code reads all the Gapminder data into Pandas DataFrames. You'll\n",
    "# learn about DataFrames next lesson.\n",
    "\n",
    "path = '/datasets/ud170/gapminder/'\n",
    "employment = pd.read_csv(path + 'employment_above_15.csv', index_col='Country')\n",
    "female_completion = pd.read_csv(path + 'female_completion_rate.csv', index_col='Country')\n",
    "male_completion = pd.read_csv(path + 'male_completion_rate.csv', index_col='Country')\n",
    "life_expectancy = pd.read_csv(path + 'life_expectancy.csv', index_col='Country')\n",
    "gdp = pd.read_csv(path + 'gdp_per_capita.csv', index_col='Country')\n",
    "\n",
    "# The following code creates a Pandas Series for each variable for the United States.\n",
    "# You can change the string 'United States' to a country of your choice.\n",
    "\n",
    "employment_us = employment.loc['United States']\n",
    "female_completion_us = female_completion.loc['United States']\n",
    "male_completion_us = male_completion.loc['United States']\n",
    "life_expectancy_us = life_expectancy.loc['United States']\n",
    "gdp_us = gdp.loc['United States']\n",
    "\n",
    "# Uncomment the following line of code to see the available country names\n",
    "# print employment.index.values\n",
    "\n",
    "# Use the Series defined above to create a plot of each variable over time for\n",
    "# the country of your choice. You will only be able to display one plot at a time\n",
    "# with each \"Test Run\".\n",
    "employment_us.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
